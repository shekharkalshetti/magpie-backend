# Nginx configuration for Magpie AI
# Optimized for LLM inference with appropriate timeouts

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # Performance
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Buffer sizes
    client_body_buffer_size 128k;
    client_max_body_size 10M;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 16k;

    # Timeouts - increased for LLM inference
    proxy_connect_timeout 90s;
    proxy_send_timeout 90s;
    proxy_read_timeout 90s;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss;

    # Rate limiting (adjust as needed)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_status 429;

    # Upstream backend
    upstream backend {
        server api:8000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # HTTP server (redirects to HTTPS in production)
    server {
        listen 80;
        server_name _;

        # Health check endpoint (bypass for load balancers)
        location /health {
            access_log off;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Uncomment for HTTPS redirect in production
        # location / {
        #     return 301 https://$host$request_uri;
        # }

        # Development: proxy all requests
        location / {
            # Rate limiting
            limit_req zone=api_limit burst=20 nodelay;

            # Proxy to FastAPI
            proxy_pass http://backend;
            proxy_http_version 1.1;
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";

            # Disable buffering for streaming responses
            proxy_buffering off;
            proxy_request_buffering off;

            # Timeouts (important for LLM inference)
            proxy_connect_timeout 90s;
            proxy_send_timeout 90s;
            proxy_read_timeout 90s;
        }
    }

    # HTTPS server (uncomment and configure for production)
    # server {
    #     listen 443 ssl http2;
    #     server_name your-domain.com;
    #
    #     # SSL certificates (use Let's Encrypt)
    #     ssl_certificate /etc/nginx/ssl/fullchain.pem;
    #     ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    #
    #     # SSL configuration
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers HIGH:!aNULL:!MD5;
    #     ssl_prefer_server_ciphers on;
    #     ssl_session_cache shared:SSL:10m;
    #     ssl_session_timeout 10m;
    #
    #     # Security headers
    #     add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    #     add_header X-Frame-Options "SAMEORIGIN" always;
    #     add_header X-Content-Type-Options "nosniff" always;
    #     add_header X-XSS-Protection "1; mode=block" always;
    #
    #     location /health {
    #         access_log off;
    #         proxy_pass http://backend;
    #         proxy_http_version 1.1;
    #         proxy_set_header Connection "";
    #     }
    #
    #     location / {
    #         limit_req zone=api_limit burst=20 nodelay;
    #
    #         proxy_pass http://backend;
    #         proxy_http_version 1.1;
    #         
    #         proxy_set_header Host $host;
    #         proxy_set_header X-Real-IP $remote_addr;
    #         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #         proxy_set_header X-Forwarded-Proto https;
    #         proxy_set_header Connection "";
    #
    #         proxy_buffering off;
    #         proxy_request_buffering off;
    #
    #         proxy_connect_timeout 90s;
    #         proxy_send_timeout 90s;
    #         proxy_read_timeout 90s;
    #     }
    # }
}
